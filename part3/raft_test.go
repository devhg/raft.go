package raft

import (
	"testing"
	"time"

	"github.com/fortytw2/leaktest"
)

func TestElectionBasic(t *testing.T) {
	h := NewHarness(t, 3)
	defer h.Shutdown()

	h.CheckSingleLeader()
}

func TestElectionLeaderDisconnect(t *testing.T) {
	h := NewHarness(t, 3)
	defer h.Shutdown()

	originLeaderID, originTerm := h.CheckSingleLeader()

	h.DisconnectPeer(originLeaderID)
	sleepMs(350)

	newLeaderID, newTerm := h.CheckSingleLeader()

	if newLeaderID == originLeaderID {
		t.Errorf("want new leader to be different from orig leader")
	}
	if newTerm <= originTerm {
		t.Errorf("want newTerm <= origTerm, got %d and %d", newTerm, originTerm)
	}
}

func TestElectionLeaderAndAnotherDisconnect(t *testing.T) {
	h := NewHarness(t, 3)
	defer h.Shutdown()

	origLeaderId, _ := h.CheckSingleLeader()

	h.DisconnectPeer(origLeaderId)
	otherId := (origLeaderId + 1) % 3
	h.DisconnectPeer(otherId)

	// No quorum.
	sleepMs(450)
	h.CheckNoLeader()

	// Reconnect one other server; now we'll have quorum.
	h.ReconnectPeer(otherId)
	h.CheckSingleLeader()
}

func TestDisconnectAllThenRestore(t *testing.T) {
	h := NewHarness(t, 3)
	defer h.Shutdown()

	sleepMs(100)
	// Disconnect all servers from the start. There will be no leader.
	for i := 0; i < 3; i++ {
		h.DisconnectPeer(i)
	}

	sleepMs(450)
	h.CheckNoLeader()

	// Reconnect all servers. A leader will be found.
	for i := 0; i < 3; i++ {
		h.ReconnectPeer(i)
	}
	h.CheckSingleLeader()
}

func TestElectionLeaderDisconnectThenReconnect(t *testing.T) {
	h := NewHarness(t, 3)
	defer h.Shutdown()

	origLeaderID, _ := h.CheckSingleLeader()

	h.DisconnectPeer(origLeaderID)
	sleepMs(350)

	newLeaderID, newTerm := h.CheckSingleLeader()

	h.ReconnectPeer(origLeaderID)
	sleepMs(450)

	againLeaderID, againTerm := h.CheckSingleLeader()

	if againLeaderID != newLeaderID {
		t.Errorf("again leader id got %d; want %d", againLeaderID, newLeaderID)
	}

	if againTerm != newTerm {
		t.Errorf("again term got %d; want %d", againTerm, againLeaderID)
	}
}

func TestElectionLeaderDisconnectThenReconnect5(t *testing.T) {
	defer leaktest.CheckTimeout(t, 100*time.Millisecond)()

	h := NewHarness(t, 5)
	defer h.Shutdown()

	origLeaderID, _ := h.CheckSingleLeader()

	h.DisconnectPeer(origLeaderID)
	sleepMs(150)

	newLeaderID, newTerm := h.CheckSingleLeader()

	h.ReconnectPeer(origLeaderID)
	sleepMs(150)

	againLeaderID, againTerm := h.CheckSingleLeader()

	if newLeaderID != againLeaderID {
		t.Errorf("again leader id got %d; want %d", againLeaderID, newLeaderID)
	}
	if againTerm != newTerm {
		t.Errorf("again term got %d; want %d", againTerm, newTerm)
	}
}

func TestElectionFollowerComesBack(t *testing.T) {
	defer leaktest.CheckTimeout(t, 100*time.Millisecond)()

	h := NewHarness(t, 3)
	defer h.Shutdown()

	origLeaderID, origTerm := h.CheckSingleLeader()
	otherID := (origLeaderID + 1) % 3

	h.DisconnectPeer(otherID)
	sleepMs(650)

	h.ReconnectPeer(otherID)
	sleepMs(150)

	// We can't have an assertion on the new leader id here because it depends
	// on the relative election timeouts. We can assert that the term changed,
	// however, which implies that re-election has occurred.
	_, newTerm := h.CheckSingleLeader()
	if newTerm <= origTerm {
		t.Errorf("newTerm=%d, origTerm=%d", newTerm, origTerm)
	}

}

func TestElectionDisconnectLoop(t *testing.T) {
	defer leaktest.CheckTimeout(t, 100*time.Millisecond)()

	h := NewHarness(t, 3)
	defer h.Shutdown()

	for cycle := 0; cycle < 5; cycle++ {
		leaderID, _ := h.CheckSingleLeader()
		h.DisconnectPeer(leaderID)

		otherID := (leaderID + 1) % 3
		h.DisconnectPeer(otherID)

		sleepMs(310)
		h.CheckNoLeader()

		// Reconnect both.
		h.ReconnectPeer(otherID)
		h.ReconnectPeer(leaderID)

		// Give it time to settle
		sleepMs(150)
	}
}

// /////////////////////////////////////////////////////////////////
func TestCommitOneCommand(t *testing.T) {
	defer leaktest.CheckTimeout(t, 100*time.Millisecond)()

	h := NewHarness(t, 3)
	defer h.Shutdown()

	origLeaderId, _ := h.CheckSingleLeader()

	tlog("submitting 42 to %d", origLeaderId)
	ok := h.SubmitToServer(origLeaderId, 42)
	if !ok {
		t.Errorf("want id=%d leader, but it's not", origLeaderId)
	}

	sleepMs(150)
	h.CheckCommittedN(42, 3)
}

func TestSubmitNonLeaderFails(t *testing.T) {
	h := NewHarness(t, 3)
	defer h.Shutdown()

	origLeaderId, _ := h.CheckSingleLeader()
	sid := (origLeaderId + 1) % 3
	tlog("submitting 42 to %d(not leader)", sid)

	ok := h.SubmitToServer(sid, 42)
	if ok {
		t.Errorf("want id=%d !leader, but it is", sid)
	}
	sleepMs(10)
}

func TestCommitMultipleCommands(t *testing.T) {
	defer leaktest.CheckTimeout(t, 100*time.Millisecond)()

	h := NewHarness(t, 3)
	defer h.Shutdown()

	origLeaderId, _ := h.CheckSingleLeader()

	values := []int{42, 55, 81}
	for _, v := range values {
		tlog("submitting %d to %d", v, origLeaderId)
		isLeader := h.SubmitToServer(origLeaderId, v)
		if !isLeader {
			t.Errorf("want id=%d leader, but it's not", origLeaderId)
		}
		sleepMs(100)
	}

	sleepMs(150)
	nc, i1 := h.CheckCommitted(42)
	_, i2 := h.CheckCommitted(55)
	if nc != 3 {
		t.Errorf("want nc=3, got %d", nc)
	}
	if i1 >= i2 {
		t.Errorf("want i1<i2, got i1=%d i2=%d", i1, i2)
	}

	_, i3 := h.CheckCommitted(81)
	if i2 >= i3 {
		t.Errorf("want i2<i3, got i2=%d i3=%d", i2, i3)
	}
}

func TestCommitWithDisconnectionAndRecover(t *testing.T) {
	defer leaktest.CheckTimeout(t, 100*time.Millisecond)()

	h := NewHarness(t, 3)
	defer h.Shutdown()

	// Submit a couple of values to a fully connected cluster.
	origLeaderId, _ := h.CheckSingleLeader()
	h.SubmitToServer(origLeaderId, 5)
	h.SubmitToServer(origLeaderId, 6)

	sleepMs(150)
	h.CheckCommittedN(6, 3)

	dPeerId := (origLeaderId + 1) % 3
	h.DisconnectPeer(dPeerId)
	sleepMs(150)

	// Submit a new command; it will be committed but only to two servers.
	h.SubmitToServer(origLeaderId, 7)
	sleepMs(150)
	h.CheckCommittedN(7, 2)

	// Now reconnect dPeerId and wait a bit; it should find the new command too.
	h.ReconnectPeer(dPeerId)

	// 400 - There may be unsuccessful re-elections
	// 这里如果时间过少，可能会出现重新选举后，日志还未同步完成的情况
	// 可以适当加大时间或重复尝试运行验证
	sleepMs(500)
	h.CheckSingleLeader()

	// dPeerId这台机器因关闭连接错过的cmd=7，会在重连后触发重新选举，新的leader会根据心跳信息
	// 把这台机器丢失cmd=7重新传给dPeerId。
	// 因此这里重新检查能够检查到三个
	h.CheckCommittedN(7, 3)
}

func TestNoCommitWithNoQuorum(t *testing.T) {
	defer leaktest.CheckTimeout(t, 100*time.Millisecond)()

	h := NewHarness(t, 3)
	defer h.Shutdown()

	// Submit a couple of values to a fully connected cluster.
	origLeaderId, origTerm := h.CheckSingleLeader()
	h.SubmitToServer(origLeaderId, 5)
	h.SubmitToServer(origLeaderId, 6)

	sleepMs(250)
	h.CheckCommittedN(6, 3)

	// Disconnect both followers.
	dPeer1 := (origLeaderId + 1) % 3
	dPeer2 := (origLeaderId + 2) % 3
	h.DisconnectPeer(dPeer1)
	h.DisconnectPeer(dPeer2)
	sleepMs(250)

	h.SubmitToServer(origLeaderId, 8)
	sleepMs(250)
	h.CheckNotCommitted(8)

	// Reconnect both other servers, we'll have quorum now.
	h.ReconnectPeer(dPeer1)
	h.ReconnectPeer(dPeer2)
	sleepMs(600)

	// 8 is still not committed because the term has changed.
	h.CheckNotCommitted(8)

	// A new leader will be elected. It could be a different leader, even though
	// the original's log is longer, because the two reconnected peers can elect
	// each other.
	newLeaderId, againTerm := h.CheckSingleLeader()
	if origTerm == againTerm {
		t.Errorf("got origTerm==againTerm==%d; want them different", origTerm)
	}

	// But new values will be committed for sure...
	h.SubmitToServer(newLeaderId, 9)
	h.SubmitToServer(newLeaderId, 10)
	h.SubmitToServer(newLeaderId, 11)
	sleepMs(350)

	for _, v := range []int{9, 10, 11} {
		h.CheckCommittedN(v, 3)
	}
}

func TestCommitsWithLeaderDisconnects(t *testing.T) {
	defer leaktest.CheckTimeout(t, 100*time.Millisecond)()

	h := NewHarness(t, 5)
	defer h.Shutdown()

	// Submit a couple of values to a fully connected cluster.
	origLeaderId, _ := h.CheckSingleLeader()
	h.SubmitToServer(origLeaderId, 5)
	h.SubmitToServer(origLeaderId, 6)

	sleepMs(150)
	h.CheckCommittedN(6, 5)

	// Leader disconnected...
	h.DisconnectPeer(origLeaderId)
	sleepMs(10)

	// Submit 7 to original leader, even though it's disconnected.
	h.SubmitToServer(origLeaderId, 7)

	sleepMs(150)
	h.CheckNotCommitted(7)

	newLeaderId, _ := h.CheckSingleLeader()

	// Submit 8 to new leader.
	h.SubmitToServer(newLeaderId, 8)
	sleepMs(150)
	h.CheckCommittedN(8, 4)

	// Reconnect old leader and let it settle. The old leader shouldn't be the one
	// winning.
	h.ReconnectPeer(origLeaderId)
	sleepMs(600)

	finalLeaderId, _ := h.CheckSingleLeader()
	if finalLeaderId == origLeaderId {
		t.Errorf("got finalLeaderId==origLeaderId==%d, want them different", finalLeaderId)
	}

	// Submit 9 and check it's fully committed.
	h.SubmitToServer(newLeaderId, 9)
	sleepMs(150)
	h.CheckCommittedN(9, 5)
	h.CheckCommittedN(8, 5)

	// But 7 is not committed...
	h.CheckNotCommitted(7)
}
